{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-10T09:35:43.047855Z",
     "start_time": "2024-12-10T09:35:35.690007Z"
    }
   },
   "outputs": [],
   "source": [
    "# import SNLI dataset from h\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"snli\")\n",
    "# Access the splits\n",
    "train_data = dataset['train']\n",
    "validation_data = dataset['validation']\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "{'premise': 'A person on a horse jumps over a broken down airplane.',\n 'hypothesis': 'A person is training his horse for a competition.',\n 'label': 1}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T09:35:46.480345Z",
     "start_time": "2024-12-10T09:35:46.470Z"
    }
   },
   "id": "1111efc1a74c64b2"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "# Define the punctuation set we care about\n",
    "PUNCT = {'.', '!', '?'}\n",
    "common_contractions = {\n",
    "    \"do not\": \"don't\",\n",
    "    \"is not\": \"isn't\",\n",
    "    \"are not\": \"aren't\",\n",
    "    \"it is\": \"it's\",\n",
    "    \"that is\": \"that's\",\n",
    "    \"we are\": \"we're\",\n",
    "    \"you are\": \"you're\",\n",
    "    \"I am\": \"I'm\",\n",
    "    \"I will\": \"I'll\",\n",
    "    \"I would\": \"I'd\",\n",
    "    \"they are\": \"they're\",\n",
    "    \"will not\": \"won't\",\n",
    "    \"can not\": \"can't\",\n",
    "    \"there is\": \"there's\"\n",
    "}\n",
    "\n",
    "def encased_with_apostrophes(text):\n",
    "    # Check if the text is encased with standard quotes (artificat in SNLI)\n",
    "    return text.startswith('\"') and text.endswith('\"')\n",
    "\n",
    "def starts_with_uppercase_word(text):\n",
    "    # Strip leading whitespace and check if the first character is uppercase\n",
    "    text = text.lstrip()\n",
    "    if not text:\n",
    "        return False\n",
    "    return text[0].isupper()\n",
    "\n",
    "def ends_with_punctuation(text):\n",
    "    # Check if the last non-whitespace character is punctuation\n",
    "    text = text.rstrip()\n",
    "    return len(text) > 0 and text[-1] in PUNCT\n",
    "\n",
    "def contains_punctuation(text):\n",
    "    # Check if there's any punctuation in the text\n",
    "    # return any(ch in string.punctuation for ch in text)\n",
    "    return any(ch in PUNCT for ch in text)\n",
    "\n",
    "def whitespace_encoding(text):\n",
    "    # Identify all distinct whitespace code points used in the text.\n",
    "    # This will differentiate between e.g. U+0020 (normal space) and U+00A0 (no-break space).\n",
    "    whitespaces = set()\n",
    "    for ch in text:\n",
    "        if ch.isspace():\n",
    "            whitespaces.add(ord(ch))  # store the code point\n",
    "    return whitespaces\n",
    "\n",
    "def apostrophe_encoding(text):\n",
    "    # Extract all apostrophe-like characters: common are `'` and `’`\n",
    "    # Return a set of apostrophe chars used\n",
    "    # If you want to be more comprehensive, include other variants.\n",
    "    # Here we include backtick and right single quotation mark as well.\n",
    "    possible_apostrophes = {\"'\", \"’\", \"`\"}\n",
    "    apostrophes = {ch for ch in text if ch in possible_apostrophes}\n",
    "    return apostrophes\n",
    "\n",
    "def extract_number_patterns(text):\n",
    "    # Find all numbers and their surrounding formatting.\n",
    "    # We'll capture substrings around each digit sequence that may include punctuation and spacing.\n",
    "    number_patterns = []\n",
    "    for match in re.finditer(r\"\\d+\", text):\n",
    "        start, end = match.span()\n",
    "        # Extend outwards to include punctuation/whitespace directly adjacent to the digits\n",
    "        left = start\n",
    "        while left > 0 and (text[left-1] in string.punctuation or text[left-1].isspace()):\n",
    "            left -= 1\n",
    "        right = end\n",
    "        while right < len(text) and (text[right] in string.punctuation or text[right].isspace()):\n",
    "            right += 1\n",
    "        substring = text[left:right].strip()\n",
    "        number_patterns.append(substring)\n",
    "    return number_patterns\n",
    "\n",
    "def compare_number_formats(patterns1, patterns2):\n",
    "    # Check if both lists have the same number of numeric patterns\n",
    "    if len(patterns1) != len(patterns2):\n",
    "        return False\n",
    "    # Compare each pair of patterns\n",
    "    for p1, p2 in zip(patterns1, patterns2):\n",
    "        # Compare digits sequence\n",
    "        digits1 = re.sub(r\"\\D\", \"\", p1)\n",
    "        digits2 = re.sub(r\"\\D\", \"\", p2)\n",
    "        if digits1 != digits2:\n",
    "            return False\n",
    "        # Compare non-digit formatting\n",
    "        non_digits1 = re.sub(r\"\\d\", \"\", p1)\n",
    "        non_digits2 = re.sub(r\"\\d\", \"\", p2)\n",
    "        if non_digits1 != non_digits2:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def contains_newline(text):\n",
    "    return \"\\n\" in text\n",
    "\n",
    "def contains_contractions(text):\n",
    "    # Check if text contains any of the known contracted forms\n",
    "    pattern = r'\\b(?:' + '|'.join(map(re.escape, common_contractions.values())) + r')\\b'\n",
    "    return bool(re.search(pattern, text, flags=re.IGNORECASE))\n",
    "\n",
    "def can_form_contractions(text):\n",
    "    # Check if text contains any expansions that could be turned into known contractions\n",
    "    # If we find at least one expansion pattern in the text, return True\n",
    "    for expansion in common_contractions.keys():\n",
    "        # Create a regex pattern for the expansion\n",
    "        exp_words = expansion.split()\n",
    "        pattern = r'\\b' + r'\\s+'.join(exp_words) + r'\\b'\n",
    "        if re.search(pattern, text, flags=re.IGNORECASE):\n",
    "            return True\n",
    "    return False\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T10:52:09.684563Z",
     "start_time": "2024-12-10T10:52:09.680765Z"
    }
   },
   "id": "1fee0ccf675459f4"
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "def compare_texts(text1, text2):\n",
    "    conditions = []\n",
    "    conditions.append(encased_with_apostrophes(text1) == encased_with_apostrophes(text2))\n",
    "    conditions.append(starts_with_uppercase_word(text1) == starts_with_uppercase_word(text2))\n",
    "    conditions.append(ends_with_punctuation(text1) == ends_with_punctuation(text2))\n",
    "    conditions.append(contains_punctuation(text1) == contains_punctuation(text2))\n",
    "    conditions.append(whitespace_encoding(text1) == whitespace_encoding(text2))\n",
    "    conditions.append(apostrophe_encoding(text1) == apostrophe_encoding(text2))\n",
    "    patterns1 = extract_number_patterns(text1)\n",
    "    patterns2 = extract_number_patterns(text2)\n",
    "    conditions.append(compare_number_formats(patterns1, patterns2))\n",
    "    conditions.append(contains_contractions(text1) == contains_contractions(text2))\n",
    "    similarity = sum(conditions) / len(conditions)\n",
    "    return similarity\n",
    "\n",
    "def make_texts_similar(text1, text2):\n",
    "    # Adjust Quotes\n",
    "    if encased_with_apostrophes(text1) != encased_with_apostrophes(text2):\n",
    "        if encased_with_apostrophes(text1) and not encased_with_apostrophes(text2):\n",
    "            text2 = '\"' + text2 + '\"'\n",
    "        elif not encased_with_apostrophes(text1) and encased_with_apostrophes(text2):\n",
    "            text2 = text2[1:-1]\n",
    "    \n",
    "    # Adjust capitalization at the start\n",
    "    if starts_with_uppercase_word(text1) != starts_with_uppercase_word(text2):\n",
    "        if starts_with_uppercase_word(text1) and not starts_with_uppercase_word(text2):\n",
    "            stripped = text2.lstrip()\n",
    "            if stripped:\n",
    "                start_idx = len(text2) - len(stripped)\n",
    "                text2 = text2[:start_idx] + stripped[0].upper() + stripped[1:]\n",
    "        elif not starts_with_uppercase_word(text1) and starts_with_uppercase_word(text2):\n",
    "            stripped = text2.lstrip()\n",
    "            if stripped:\n",
    "                start_idx = len(text2) - len(stripped)\n",
    "                text2 = text2[:start_idx] + stripped[0].lower() + stripped[1:]\n",
    "\n",
    "    # Adjust punctuation at the end\n",
    "    if ends_with_punctuation(text1) != ends_with_punctuation(text2):\n",
    "        if ends_with_punctuation(text1) and not ends_with_punctuation(text2):\n",
    "            t1_end_punct = text1.rstrip()[-1]\n",
    "            text2 = text2.rstrip() + t1_end_punct\n",
    "        elif not ends_with_punctuation(text1) and ends_with_punctuation(text2):\n",
    "            text2 = text2.rstrip()\n",
    "            while text2 and text2[-1] in PUNCT:\n",
    "                text2 = text2[:-1]\n",
    "\n",
    "    # Now text1 and text2 should be similar in capitalization and end punctuation.\n",
    "    # Apostrophe and whitespace encoding is the same initially.\n",
    "    # Randomly decide if we want to change them for BOTH texts simultaneously.\n",
    "    \n",
    "    # Random chance to change whitespace encoding for both\n",
    "    # For example, replace all regular spaces with non-breaking spaces in both texts\n",
    "    if random.random() < 0.5:\n",
    "        # Check if we have spaces\n",
    "        if \" \" in text1 or \" \" in text2:\n",
    "            # Replace all spaces with non-breaking spaces\n",
    "            text1 = text1.replace(\" \", \"\\u00A0\")\n",
    "            text2 = text2.replace(\" \", \"\\u00A0\")\n",
    "\n",
    "    # Random chance to toggle apostrophe encoding for both\n",
    "    # If we have apostrophes, switch them from `'` to `’` or vice versa\n",
    "    apos1 = apostrophe_encoding(text1)\n",
    "    apos2 = apostrophe_encoding(text2)\n",
    "    # Since they are initially the same, we can just pick a toggle.\n",
    "    if random.random() < 0.5 and (apos1 and apos2):\n",
    "        # If we have at least one type of apostrophe in the texts\n",
    "        # If we find `'` in texts, replace it with `’`, else if `’` then replace with `'`\n",
    "        if \"'\" in text1 or \"'\" in text2:\n",
    "            # Replace `'` with `’`\n",
    "            text1 = text1.replace(\"'\", \"’\")\n",
    "            text2 = text2.replace(\"'\", \"’\")\n",
    "        elif \"’\" in text1 or \"’\" in text2:\n",
    "            # Replace `’` with `'`\n",
    "            text1 = text1.replace(\"’\", \"'\")\n",
    "            text2 = text2.replace(\"’\", \"'\")\n",
    "\n",
    "    return text1, text2\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T10:52:10.078577Z",
     "start_time": "2024-12-10T10:52:10.076088Z"
    }
   },
   "id": "3dd4afabfbbafb88"
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def flip_quotes(t):\n",
    "    if encased_with_apostrophes(t):\n",
    "        return t[1:-1], True\n",
    "    else:\n",
    "        return '\"' + t + '\"', True\n",
    "    \n",
    "def flip_capitalization(t):\n",
    "    stripped = t.lstrip()\n",
    "    if not stripped:\n",
    "        return t, False\n",
    "    start_idx = len(t) - len(stripped)\n",
    "    first_char = stripped[0]\n",
    "    if first_char.isalpha():\n",
    "        flipped = first_char.lower() if first_char.isupper() else first_char.upper()\n",
    "        new_t = t[:start_idx] + flipped + stripped[1:]\n",
    "        changed = (new_t != t)\n",
    "        return new_t, changed\n",
    "    else:\n",
    "        return t, False\n",
    "\n",
    "def toggle_end_punctuation(t):\n",
    "    if ends_with_punctuation(t):\n",
    "        original = t\n",
    "        t = t.rstrip()\n",
    "        while t and t[-1] in PUNCT:\n",
    "            t = t[:-1]\n",
    "        changed = (t != original)\n",
    "        return t, changed\n",
    "    else:\n",
    "        return t + \".\", True\n",
    "\n",
    "# def toggle_punctuation_presence(t):\n",
    "#     if contains_punctuation(t):\n",
    "#         original = t\n",
    "#         t = \"\".join(ch for ch in t if ch not in PUNCT).rstrip()\n",
    "#         changed = (t != original)\n",
    "#         return t, changed\n",
    "#     else:\n",
    "#         return t, False\n",
    "\n",
    "def toggle_whitespace_encoding(t):\n",
    "    # Assume it only includes \" \" whitespaces. Change those to non-breaking spaces (\\u00A0)\n",
    "    original = t\n",
    "    if \" \" in t:\n",
    "        # Replace all spaces with non-breaking spaces\n",
    "        t = t.replace(\" \", \"\\u00A0\")\n",
    "        changed = (t != original)\n",
    "        return t, changed\n",
    "    else:\n",
    "        # No spaces to change\n",
    "        return t, False\n",
    "\n",
    "def toggle_apostrophe_encoding(t):\n",
    "    original = t\n",
    "    apos = apostrophe_encoding(t)\n",
    "    if apos:\n",
    "        if \"'\" in apos and \"’\" in apos:\n",
    "            t = t.replace(\"'\", \"\\uFFFF\")\n",
    "            t = t.replace(\"’\", \"'\")\n",
    "            t = t.replace(\"\\uFFFF\", \"’\")\n",
    "        elif \"'\" in apos:\n",
    "            t = t.replace(\"'\", \"’\")\n",
    "        elif \"’\" in apos:\n",
    "            t = t.replace(\"’\", \"'\")\n",
    "        changed = (t != original)\n",
    "        return t, changed\n",
    "    else:\n",
    "        return t, False\n",
    "\n",
    "def toggle_number_format(t):\n",
    "    patterns = extract_number_patterns(t)\n",
    "    changed = False\n",
    "    if patterns:\n",
    "        for p in patterns:\n",
    "            if ',' in p:\n",
    "                new_p = re.sub(r\",\", \"\", p)\n",
    "                if new_p != p:\n",
    "                    idx = t.find(p)\n",
    "                    if idx != -1:\n",
    "                        t = t[:idx] + new_p + t[idx+len(p):]\n",
    "                        changed = True\n",
    "                        break\n",
    "    return t, changed\n",
    "\n",
    "def maybe_add_contraction(text1, text2):\n",
    "    # Only add a contraction if:\n",
    "    # - text1 can form contractions\n",
    "    # - text1 has no contractions\n",
    "    # - text2 has no contractions\n",
    "    original = text2\n",
    "    if not can_form_contractions(text1):\n",
    "        return text2, False\n",
    "    if contains_contractions(text1) or contains_contractions(text2):\n",
    "        return text2, False\n",
    "\n",
    "    expansions = list(common_contractions.keys())\n",
    "    random.shuffle(expansions)\n",
    "\n",
    "    for expansion in expansions:\n",
    "        exp_words = expansion.split()\n",
    "        pattern = r'\\b' + r'\\s+'.join(exp_words) + r'\\b'\n",
    "        match = re.search(pattern, text2, flags=re.IGNORECASE)\n",
    "        if match:\n",
    "            contraction = common_contractions[expansion]\n",
    "            matched_text = match.group(0)\n",
    "            if matched_text[0].isupper():\n",
    "                contraction = contraction[0].upper() + contraction[1:]\n",
    "            text2 = text2[:match.start()] + contraction + text2[match.end():]\n",
    "            return text2, (text2 != original)\n",
    "\n",
    "    return text2, False\n",
    "\n",
    "def make_texts_distinct(text1, text2):\n",
    "    initial_similarity = compare_texts(text1, text2)\n",
    "    if initial_similarity < 1.0:\n",
    "        # Already distinct enough (final similarity < initial similarity would mean final < initial)\n",
    "        # but user wants strictly less than initial. Let's try to reduce further.\n",
    "        target_similarity = 0.0 if initial_similarity == 0.0 else (initial_similarity - 0.01)\n",
    "    else:\n",
    "        # initial_similarity is 1.0 or close to it, we must get below that (e.g., <1.0)\n",
    "        target_similarity = initial_similarity - 0.01\n",
    "\n",
    "    transformations = [\n",
    "        flip_quotes,\n",
    "        flip_capitalization,\n",
    "        toggle_end_punctuation,\n",
    "        toggle_whitespace_encoding,\n",
    "        toggle_apostrophe_encoding,\n",
    "        toggle_number_format,\n",
    "        lambda t: maybe_add_contraction(text1, t),\n",
    "    ]\n",
    "\n",
    "    # Try transformations until we achieve a final similarity less than initial_similarity\n",
    "    # We'll try each transformation one by one and apply only if it reduces similarity.\n",
    "\n",
    "    # Because we want to ensure difference, we may attempt multiple transformations.\n",
    "    # We'll try a randomized approach: shuffle transformations and try them repeatedly\n",
    "    # until we either succeed or exhaust attempts.\n",
    "    text_modified = text2\n",
    "    attempts = 20  # limit attempts to avoid infinite loops\n",
    "\n",
    "    while attempts > 0:\n",
    "        current_similarity = compare_texts(text1, text_modified)\n",
    "        if current_similarity < initial_similarity:\n",
    "            # We've achieved our goal: final similarity is less than initial\n",
    "            return text_modified\n",
    "\n",
    "        # Attempt a random transformation\n",
    "        transform = random.choice(transformations)\n",
    "        new_text, changed = transform(text_modified)\n",
    "        if changed:\n",
    "            # Check if similarity improved (decreased)\n",
    "            new_similarity = compare_texts(text1, new_text)\n",
    "            if new_similarity < current_similarity:\n",
    "                # Keep this change\n",
    "                text_modified = new_text\n",
    "            # If new_similarity is not lower, revert to old text_modified (no change applied)\n",
    "        attempts -= 1\n",
    "\n",
    "    # If we exit the loop, we failed to reduce similarity\n",
    "    return text_modified"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T10:52:10.374403Z",
     "start_time": "2024-12-10T10:52:10.370458Z"
    }
   },
   "id": "15964367d2573682"
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.875\n"
     ]
    }
   ],
   "source": [
    "text_a = \"Hello, world!\"\n",
    "text_b = \"Hello,\\u00a0world!\"\n",
    "score = compare_texts(text_a, text_b)\n",
    "print(\"Similarity score:\", score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T10:52:10.710574Z",
     "start_time": "2024-12-10T10:52:10.707517Z"
    }
   },
   "id": "7ed8d149c3e0256"
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.25\n"
     ]
    }
   ],
   "source": [
    "text_a = \"Hello, world!\\nThe price is 1,000 dollars. It’s great.\"\n",
    "text_b = \"hello world. The price is 1000 dollars It's great\"\n",
    "score = compare_texts(text_a, text_b)\n",
    "print(\"Similarity score:\", score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T10:52:12.869274Z",
     "start_time": "2024-12-10T10:52:12.861014Z"
    }
   },
   "id": "53603be18299f695"
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.75\n",
      "Synthesized text: Men are working on John Deere equipment.\n",
      "Similarity score: 1.0\n"
     ]
    }
   ],
   "source": [
    "text_a = \"The two farmers are working on a piece of John Deere equipment.\"\n",
    "text_b = \"Men are working on John Deere equipment\"\n",
    "score = compare_texts(text_a, text_b)\n",
    "print(\"Similarity score:\", score)\n",
    "text_b_synth = make_texts_similar(text_a, text_b)[1]\n",
    "print(\"Synthesized text:\", text_b_synth)\n",
    "score = compare_texts(text_a, text_b_synth)\n",
    "print(\"Similarity score:\", score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T10:52:30.329530Z",
     "start_time": "2024-12-10T10:52:30.325810Z"
    }
   },
   "id": "60acb039abe67d71"
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 1.0\n",
      "Synthesized text: \"There is a party\"\n",
      "Similarity score: 0.75\n"
     ]
    }
   ],
   "source": [
    "text_a = \"There is a party\"\n",
    "text_b = \"There is a party\"\n",
    "score = compare_texts(text_a, text_b)\n",
    "print(\"Similarity score:\", score)\n",
    "text_b_synth = make_texts_distinct(text_a, text_b)\n",
    "print(\"Synthesized text:\", text_b_synth)\n",
    "score = compare_texts(text_a, text_b_synth)\n",
    "print(\"Similarity score:\", score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T10:52:36.397729Z",
     "start_time": "2024-12-10T10:52:36.393678Z"
    }
   },
   "id": "95956ea770054e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Augmentation for SNLI"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d54e1e41b64ba7d"
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dataset = load_dataset(\"snli\")\n",
    "os.makedirs(\"snli_modified\", exist_ok=True)\n",
    "\n",
    "for split in dataset.keys():\n",
    "    data = dataset[split]\n",
    "\n",
    "    rows = []\n",
    "    for example in data:\n",
    "        premise = example[\"premise\"]\n",
    "        hypothesis = example[\"hypothesis\"]\n",
    "        label = example[\"label\"]\n",
    "\n",
    "        # Skip if label is not in {0, 1, 2}\n",
    "        if label not in {0, 1, 2}:\n",
    "            continue\n",
    "\n",
    "        # Flip a coin for similar/distinct\n",
    "        want_similar = random.choice([True, False])\n",
    "\n",
    "        # Check current similarity\n",
    "        initial_sim = compare_texts(premise, hypothesis)\n",
    "        currently_similar = (initial_sim == 1.0)\n",
    "\n",
    "        if want_similar and not currently_similar:\n",
    "            # Make them similar\n",
    "            premise, hypothesis = make_texts_similar(premise, hypothesis)\n",
    "        elif not want_similar and currently_similar:\n",
    "            # Make them distinct\n",
    "            hypothesis = make_texts_distinct(premise, hypothesis)\n",
    "\n",
    "        # Re-check similarity after transformations\n",
    "        final_sim = compare_texts(premise, hypothesis)\n",
    "        style = 1 if final_sim == 1.0 else 0 # 1 for similar, 0 for distinct\n",
    "\n",
    "        rows.append({\n",
    "            \"premise\": premise,\n",
    "            \"hypothesis\": hypothesis,\n",
    "            \"label\": label, # 0 entailment, 1 neutral, 2 contradiction\n",
    "            \"style\": style # 0 distinct, 1 similar\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"premise\", \"hypothesis\", \"label\", \"style\"])\n",
    "    output_file = f\"snli_modified/{split}_modified.csv\"\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T10:55:26.399309Z",
     "start_time": "2024-12-10T10:54:30.352575Z"
    }
   },
   "id": "498d9a270007d867"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5e5b745063e02459"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
